{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"fnVYJltfN8TN","executionInfo":{"status":"ok","timestamp":1668505039266,"user_tz":-330,"elapsed":4665,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[],"source":["import os\n","import string\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","from keras.utils import to_categorical\n","from keras.utils.data_utils import get_file\n","from keras.models import Sequential, load_model\n","from keras.layers import Embedding, LSTM, Dense\n","from keras.callbacks import EarlyStopping, ModelCheckpoint"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f20QV-yaNZas","outputId":"4ae85f05-12bb-4005-ab52-86e660ddf435","executionInfo":{"status":"ok","timestamp":1668505039267,"user_tz":-330,"elapsed":3,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["corpus length: 600893\n","example text: PREFACE\n","\n","\n","SUPPOSING that Truth is a woman--what then? Is there not ground\n","for suspecting that all philosophers, in so far as they have been\n","dogmatists\n"]}],"source":["path=get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","with open(path, encoding='utf-8') as f:\n","    raw_text=f.read()\n","\n","print('corpus length:',len(raw_text))\n","print('example text:',raw_text[:150])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-qGtVG3CN-hX","executionInfo":{"status":"ok","timestamp":1668505040904,"user_tz":-330,"elapsed":1025,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[],"source":["tokens=raw_text.replace('--', ' ').split()\n","cleaned_tokens=[]\n","table=str.maketrans('','', string.punctuation)\n","for word in tokens:\n","    word=word.translate(table)\n","    if word.isalpha():\n","        cleaned_tokens.append(word.lower())"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N769sVlrTYw6","outputId":"55cf8fe2-b36c-4885-e6ce-16e91ceb42f4","executionInfo":{"status":"ok","timestamp":1668505042907,"user_tz":-330,"elapsed":2,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["vocabulary size:  5090\n","filtered words:  5097\n"]}],"source":["min_count=2\n","unknown_token='<unk>'\n","word2index={unknown_token: 0}\n","index2word=[unknown_token]\n","\n","filtered_words=0\n","counter=Counter(cleaned_tokens)\n","for word, count in counter.items():\n","    if count>=min_count:\n","        index2word.append(word)\n","        word2index[word]=len(word2index)\n","    else:\n","        filtered_words+=1\n","\n","num_classes=len(word2index)\n","print('vocabulary size: ',num_classes)\n","print('filtered words: ',filtered_words)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ToHcYnRcTvOq","outputId":"2e5b35d0-3790-463f-ffee-c946455e6ea7","executionInfo":{"status":"ok","timestamp":1668505046214,"user_tz":-330,"elapsed":1313,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["sequence dimension:  (33342, 40)\n","target dimension:  (33342, 5090)\n","example sequence:\n"," [ 1  2  3  4  5  6  7  8  9  5 10 11 12 13  0  3 14 15 16 17 18 19 20 21\n"," 22 23 21 24 25 26 27  3 28 29 30 31 32  0 33 34]\n"]}],"source":["step=3\n","maxlen=40\n","X=[]\n","y=[]\n","for i in range(0,len(cleaned_tokens)-maxlen,step):\n","    sentence=cleaned_tokens[i:i+maxlen]\n","    next_word=cleaned_tokens[i+maxlen]\n","    X.append([word2index.get(word,0) for word in sentence])\n","    y.append(word2index.get(next_word,0))\n","X=np.array(X)\n","Y=to_categorical(y,num_classes)\n","print('sequence dimension: ',X.shape)\n","print('target dimension: ',Y.shape)\n","print('example sequence:\\n',X[0])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aUCkOYRfVDyb","outputId":"9eb9d21b-87fc-4466-d1d0-e54d48957530","executionInfo":{"status":"ok","timestamp":1668505048628,"user_tz":-330,"elapsed":1473,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 40, 50)            254500    \n","                                                                 \n"," lstm (LSTM)                 (None, 256)               314368    \n","                                                                 \n"," dense (Dense)               (None, 5090)              1308130   \n","                                                                 \n","=================================================================\n","Total params: 1,876,998\n","Trainable params: 1,876,998\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["embedding_size=50\n","lstm_size=256\n","model1=Sequential()\n","model1.add(Embedding(num_classes,embedding_size,input_length=maxlen))\n","model1.add(LSTM(lstm_size))\n","model1.add(Dense(num_classes,activation='softmax'))\n","model1.compile(loss='categorical_crossentropy',optimizer='adam')\n","print(model1.summary())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MnLrPhgVmqq","outputId":"0969ff61-dee4-482a-8ba2-5b786995a3a0","executionInfo":{"status":"ok","timestamp":1668505087731,"user_tz":-330,"elapsed":33833,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["model checkpoint address:  lstm_weights1.hdf5\n","Epoch 1/5\n","834/834 [==============================] - 10s 8ms/step - loss: 6.3659 - val_loss: 6.2693\n","Epoch 2/5\n","834/834 [==============================] - 6s 7ms/step - loss: 5.9222 - val_loss: 6.2270\n","Epoch 3/5\n","834/834 [==============================] - 6s 8ms/step - loss: 5.7223 - val_loss: 6.2398\n","Epoch 4/5\n","834/834 [==============================] - 6s 7ms/step - loss: 5.5509 - val_loss: 6.2701\n","Epoch 5/5\n","834/834 [==============================] - 6s 7ms/step - loss: 5.3692 - val_loss: 6.3668\n"]}],"source":["epochs=5\n","batch_size=32\n","validation_split=0.2\n","address1='lstm_weights1.hdf5'\n","print('model checkpoint address: ',address1)\n","\n","history=model1.fit(X,Y,batch_size=batch_size, \n","                            epochs=epochs, verbose=1,\n","                            validation_split=validation_split)\n","\n","model_info={'history': history,'model':model1}\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"GEw_P2PxW-8-","executionInfo":{"status":"ok","timestamp":1668505092433,"user_tz":-330,"elapsed":537,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[],"source":["def check_prediction(model, num_predict):\n","    true_print_out='Actual words: '\n","    pred_print_out='Predicted words: '\n","    for i in range(num_predict):\n","        x=X[i]\n","        prediction=model.predict(x[np.newaxis, :], verbose = 0)\n","        index=np.argmax(prediction)\n","        true_print_out+=index2word[y[i]]+' '\n","        pred_print_out+=index2word[index]+' '\n","\n","    print(true_print_out)\n","    print(pred_print_out)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvM_10uqcghr","outputId":"b41dd259-840f-40f5-e3e5-572336cdc32c","executionInfo":{"status":"ok","timestamp":1668505096572,"user_tz":-330,"elapsed":1522,"user":{"displayName":"Charanjeet Singh","userId":"06679633166030993964"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Actual words: they paid to been unseemly <unk> certainly never to and \n","Predicted words: the and of the <unk> the and the is and \n"]}],"source":["num_predict=10\n","model=model_info['model']\n","check_prediction(model,num_predict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1sTgsHAdvx0"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}