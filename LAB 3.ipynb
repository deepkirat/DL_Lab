{"cells":[{"cell_type":"markdown","id":"8ffada24","metadata":{"id":"8ffada24"},"source":["# Lab 3: Build a FFN Network to solve a Multi- class classification problem"]},{"cell_type":"code","execution_count":null,"id":"cbb0e928","metadata":{"id":"cbb0e928"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import np_utils\n","from keras.layers import Dense\n","from keras.models import Sequential\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"id":"65fa2f17","metadata":{"scrolled":true,"id":"65fa2f17","outputId":"dfcdc4d6-f9e3-4a96-c304-1b9dc2ec2590"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["     petal_length  petal_width  sepal_length  sepal_width           label\n","0             5.1          3.5           1.4          0.2     Iris-setosa\n","1             4.9          3.0           1.4          0.2     Iris-setosa\n","2             4.7          3.2           1.3          0.2     Iris-setosa\n","3             4.6          3.1           1.5          0.2     Iris-setosa\n","4             5.0          3.6           1.4          0.2     Iris-setosa\n","..            ...          ...           ...          ...             ...\n","145           6.7          3.0           5.2          2.3  Iris-virginica\n","146           6.3          2.5           5.0          1.9  Iris-virginica\n","147           6.5          3.0           5.2          2.0  Iris-virginica\n","148           6.2          3.4           5.4          2.3  Iris-virginica\n","149           5.9          3.0           5.1          1.8  Iris-virginica\n","\n","[150 rows x 5 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"id":"790e207e","metadata":{"id":"790e207e","outputId":"bfa177cb-895c-44d0-e9fb-7c1c92c1721c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","      <td>150.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>5.843333</td>\n","      <td>3.054000</td>\n","      <td>3.758667</td>\n","      <td>1.198667</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.828066</td>\n","      <td>0.433594</td>\n","      <td>1.764420</td>\n","      <td>0.763161</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>4.300000</td>\n","      <td>2.000000</td>\n","      <td>1.000000</td>\n","      <td>0.100000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5.100000</td>\n","      <td>2.800000</td>\n","      <td>1.600000</td>\n","      <td>0.300000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>5.800000</td>\n","      <td>3.000000</td>\n","      <td>4.350000</td>\n","      <td>1.300000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>6.400000</td>\n","      <td>3.300000</td>\n","      <td>5.100000</td>\n","      <td>1.800000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>7.900000</td>\n","      <td>4.400000</td>\n","      <td>6.900000</td>\n","      <td>2.500000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       petal_length  petal_width  sepal_length  sepal_width\n","count    150.000000   150.000000    150.000000   150.000000\n","mean       5.843333     3.054000      3.758667     1.198667\n","std        0.828066     0.433594      1.764420     0.763161\n","min        4.300000     2.000000      1.000000     0.100000\n","25%        5.100000     2.800000      1.600000     0.300000\n","50%        5.800000     3.000000      4.350000     1.300000\n","75%        6.400000     3.300000      5.100000     1.800000\n","max        7.900000     4.400000      6.900000     2.500000"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.describe()"]},{"cell_type":"code","execution_count":null,"id":"14e52137","metadata":{"scrolled":true,"id":"14e52137","outputId":"5c6b3f6e-9e8a-4fb3-d2d7-da7104324652"},"outputs":[{"data":{"text/plain":["petal_length    0\n","petal_width     0\n","sepal_length    0\n","sepal_width     0\n","label           0\n","dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()"]},{"cell_type":"code","execution_count":null,"id":"7dd9d389","metadata":{"id":"7dd9d389","outputId":"cec74d34-bc22-4d67-a905-df43e7f9c0b8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>petal_length</th>\n","      <th>petal_width</th>\n","      <th>sepal_length</th>\n","      <th>sepal_width</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>6.3</td>\n","      <td>2.5</td>\n","      <td>5.0</td>\n","      <td>1.9</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>6.5</td>\n","      <td>3.0</td>\n","      <td>5.2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>6.2</td>\n","      <td>3.4</td>\n","      <td>5.4</td>\n","      <td>2.3</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>5.9</td>\n","      <td>3.0</td>\n","      <td>5.1</td>\n","      <td>1.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 4 columns</p>\n","</div>"],"text/plain":["     petal_length  petal_width  sepal_length  sepal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           1.3          0.2\n","3             4.6          3.1           1.5          0.2\n","4             5.0          3.6           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X = data.iloc[:,0:4]\n","X "]},{"cell_type":"code","execution_count":null,"id":"9266fb9e","metadata":{"id":"9266fb9e","outputId":"c2c726ad-f115-484d-8f30-2df07b13e16a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>Iris-virginica</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 1 columns</p>\n","</div>"],"text/plain":["              label\n","0       Iris-setosa\n","1       Iris-setosa\n","2       Iris-setosa\n","3       Iris-setosa\n","4       Iris-setosa\n","..              ...\n","145  Iris-virginica\n","146  Iris-virginica\n","147  Iris-virginica\n","148  Iris-virginica\n","149  Iris-virginica\n","\n","[150 rows x 1 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["Y = data.iloc[:,4:]\n","Y"]},{"cell_type":"code","execution_count":null,"id":"473a79a5","metadata":{"id":"473a79a5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"83b910fa","metadata":{"scrolled":true,"id":"83b910fa","outputId":"dbf90e5b-57ab-4a36-c7ff-cde15235f7f4"},"outputs":[{"data":{"text/plain":["array([[1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 1., 0.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.],\n","       [0., 0., 1.]], dtype=float32)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["dummy_Y"]},{"cell_type":"code","execution_count":null,"id":"1f959434","metadata":{"id":"1f959434"},"outputs":[],"source":["X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_Y, test_size = 20, random_state = 1)"]},{"cell_type":"code","execution_count":null,"id":"89e5f7a7","metadata":{"scrolled":true,"id":"89e5f7a7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"efd034e2","metadata":{"id":"efd034e2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"83b9463d","metadata":{"scrolled":true,"id":"83b9463d","outputId":"c64b4159-27e0-4530-bca7-9ed0070a8053"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/200\n","5/5 [==============================] - 1s 2ms/step - loss: 1.2917 - accuracy: 0.3538\n","Epoch 2/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.2233 - accuracy: 0.3538\n","Epoch 3/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.1701 - accuracy: 0.3538\n","Epoch 4/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.1301 - accuracy: 0.3538\n","Epoch 5/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.1085 - accuracy: 0.3538\n","Epoch 6/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0937 - accuracy: 0.3538\n","Epoch 7/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0856 - accuracy: 0.3538\n","Epoch 8/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0782 - accuracy: 0.3538\n","Epoch 9/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0742 - accuracy: 0.3538\n","Epoch 10/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.3538\n","Epoch 11/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.3538\n","Epoch 12/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0648 - accuracy: 0.3538\n","Epoch 13/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0616 - accuracy: 0.3538\n","Epoch 14/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0604 - accuracy: 0.3692\n","Epoch 15/200\n","5/5 [==============================] - 0s 1ms/step - loss: 1.0563 - accuracy: 0.3923\n","Epoch 16/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.4000\n","Epoch 17/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0493 - accuracy: 0.3769\n","Epoch 18/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0457 - accuracy: 0.3846\n","Epoch 19/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.3692\n","Epoch 20/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.3692\n","Epoch 21/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.3846\n","Epoch 22/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0289 - accuracy: 0.4538\n","Epoch 23/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0245 - accuracy: 0.6000\n","Epoch 24/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.6769\n","Epoch 25/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0151 - accuracy: 0.6769\n","Epoch 26/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.6769\n","Epoch 27/200\n","5/5 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.6769\n","Epoch 28/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9963 - accuracy: 0.6769\n","Epoch 29/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.6769\n","Epoch 30/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9823 - accuracy: 0.6769\n","Epoch 31/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9749 - accuracy: 0.6769\n","Epoch 32/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9648 - accuracy: 0.6769\n","Epoch 33/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.6769\n","Epoch 34/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9485 - accuracy: 0.6769\n","Epoch 35/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9381 - accuracy: 0.6769\n","Epoch 36/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9305 - accuracy: 0.6769\n","Epoch 37/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9187 - accuracy: 0.6769\n","Epoch 38/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6769\n","Epoch 39/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.6769\n","Epoch 40/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8853 - accuracy: 0.6769\n","Epoch 41/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8753 - accuracy: 0.6769\n","Epoch 42/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.8633 - accuracy: 0.6769\n","Epoch 43/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.6769\n","Epoch 44/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8393 - accuracy: 0.6769\n","Epoch 45/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8290 - accuracy: 0.6769\n","Epoch 46/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8208 - accuracy: 0.6769\n","Epoch 47/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.8113 - accuracy: 0.6923\n","Epoch 48/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7961 - accuracy: 0.6923\n","Epoch 49/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.6769\n","Epoch 50/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.6769\n","Epoch 51/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7544 - accuracy: 0.6769\n","Epoch 52/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7441 - accuracy: 0.6769\n","Epoch 53/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7323 - accuracy: 0.6769\n","Epoch 54/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.6769\n","Epoch 55/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.7087 - accuracy: 0.6769\n","Epoch 56/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.6769\n","Epoch 57/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.6769\n","Epoch 58/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6760 - accuracy: 0.6769\n","Epoch 59/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6769\n","Epoch 60/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6769\n","Epoch 61/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6769\n","Epoch 62/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6769\n","Epoch 63/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.6769\n","Epoch 64/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.6769\n","Epoch 65/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6923\n","Epoch 66/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.6040 - accuracy: 0.7077\n","Epoch 67/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.7154\n","Epoch 68/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7231\n","Epoch 69/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7231\n","Epoch 70/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.7077\n","Epoch 71/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7077\n","Epoch 72/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7308\n","Epoch 73/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7538\n","Epoch 74/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7615\n","Epoch 75/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7154\n","Epoch 76/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7692\n","Epoch 77/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8692\n","Epoch 78/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8154\n","Epoch 79/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7615\n","Epoch 80/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7769\n","Epoch 81/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7846\n","Epoch 82/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8615\n","Epoch 83/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.9308\n","Epoch 84/200\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.9385\n","Epoch 85/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8692\n","Epoch 86/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.9231\n","Epoch 87/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8538\n","Epoch 88/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7462\n","Epoch 89/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7154\n","Epoch 90/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8385\n","Epoch 91/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.9385\n","Epoch 92/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.9385\n","Epoch 93/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.9385\n","Epoch 94/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.9385\n","Epoch 95/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.9308\n","Epoch 96/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.4167 - accuracy: 0.8923\n","Epoch 97/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8846\n","Epoch 98/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.9231\n","Epoch 99/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.9000\n","Epoch 100/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3909 - accuracy: 0.9077\n","Epoch 101/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.9231\n","Epoch 102/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3817 - accuracy: 0.9000\n","Epoch 103/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.9000\n","Epoch 104/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.9385\n","Epoch 105/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.9385\n","Epoch 106/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.9308\n","Epoch 107/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.9077\n","Epoch 108/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.9077\n","Epoch 109/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.9385\n","Epoch 110/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.9462\n","Epoch 111/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.9462\n","Epoch 112/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.9385\n","Epoch 113/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.9308\n","Epoch 114/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.9000\n","Epoch 115/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.9000\n","Epoch 116/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.9308\n","Epoch 117/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3145 - accuracy: 0.9308\n","Epoch 118/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.9615\n","Epoch 119/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.9308\n","Epoch 120/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2967 - accuracy: 0.9538\n","Epoch 121/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.9462\n","Epoch 122/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.9385\n","Epoch 123/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2829 - accuracy: 0.9462\n","Epoch 124/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2851 - accuracy: 0.9308\n","Epoch 125/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.9462\n","Epoch 126/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2709 - accuracy: 0.9538\n","Epoch 127/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9385\n","Epoch 128/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.9308\n","Epoch 129/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9385\n","Epoch 130/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2688 - accuracy: 0.9154\n","Epoch 131/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9538\n","Epoch 132/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9538\n","Epoch 133/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9462\n","Epoch 134/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9462\n","Epoch 135/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.9538\n","Epoch 136/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9308\n","Epoch 137/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8769\n","Epoch 138/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9462\n","Epoch 139/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2534 - accuracy: 0.9154\n","Epoch 140/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2321 - accuracy: 0.9462\n","Epoch 141/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9462\n","Epoch 142/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2274 - accuracy: 0.9308\n","Epoch 143/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9462\n","Epoch 144/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2379 - accuracy: 0.9154\n","Epoch 145/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.9538\n","Epoch 146/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.9462\n","Epoch 147/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9462\n","Epoch 148/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2081 - accuracy: 0.9462\n","Epoch 149/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2054 - accuracy: 0.9385\n","Epoch 150/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9615\n","Epoch 151/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9615\n","Epoch 152/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.9462\n","Epoch 153/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.9538\n","Epoch 154/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.9538\n","Epoch 155/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9462\n","Epoch 156/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1916 - accuracy: 0.9462\n","Epoch 157/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9538\n","Epoch 158/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9154\n","Epoch 159/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.9538\n","Epoch 160/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.8846\n","Epoch 161/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8000\n","Epoch 162/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1905 - accuracy: 0.9462\n","Epoch 163/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9154\n","Epoch 164/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.9308\n","Epoch 165/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9615\n","Epoch 166/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.9231\n","Epoch 167/200\n"]},{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.9385\n","Epoch 168/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.9615\n","Epoch 169/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9615\n","Epoch 170/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9538\n","Epoch 171/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9615\n","Epoch 172/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9538\n","Epoch 173/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9538\n","Epoch 174/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.9462\n","Epoch 175/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.9385\n","Epoch 176/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9538\n","Epoch 177/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9538\n","Epoch 178/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.9615\n","Epoch 179/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9538\n","Epoch 180/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9385\n","Epoch 181/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9385\n","Epoch 182/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9385\n","Epoch 183/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.9538\n","Epoch 184/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9615\n","Epoch 185/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9615\n","Epoch 186/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9538\n","Epoch 187/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9462\n","Epoch 188/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1481 - accuracy: 0.9615\n","Epoch 189/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9615\n","Epoch 190/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1465 - accuracy: 0.9615\n","Epoch 191/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1419 - accuracy: 0.9615\n","Epoch 192/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9538\n","Epoch 193/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9538\n","Epoch 194/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9538\n","Epoch 195/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9308\n","Epoch 196/200\n","5/5 [==============================] - 0s 2ms/step - loss: 0.1514 - accuracy: 0.9308\n","Epoch 197/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9538\n","Epoch 198/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9231\n","Epoch 199/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.9615\n","Epoch 200/200\n","5/5 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9538\n"]}],"source":["history = model.fit(X_train, Y_train, epochs = 200, batch_size = 32) "]},{"cell_type":"code","execution_count":null,"id":"0733f274","metadata":{"id":"0733f274","outputId":"d9e6596c-a9d1-455e-d8ca-265b736678bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9385\n"]}],"source":["loss, accuracy = model.evaluate(X_train, Y_train)"]},{"cell_type":"code","execution_count":null,"id":"27ccc3ef","metadata":{"id":"27ccc3ef","outputId":"58602cad-552c-48f7-a537-c3d06cedb564"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 93.85% Loss: 15.11%\n"]}],"source":["print(\"Accuracy: %.2f%% Loss: %.2f%%\" % (accuracy*100, loss*100))"]},{"cell_type":"code","execution_count":null,"id":"369454c8","metadata":{"id":"369454c8","outputId":"67bc2d70-5352-48e8-aa80-6b7c5dc9ce07"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 85ms/step\n"]}],"source":["Actual = np.argmax(model.predict(X_test),axis=1)"]},{"cell_type":"code","execution_count":null,"id":"41f4a6ea","metadata":{"id":"41f4a6ea","outputId":"2d9e40a7-9d19-4b22-89be-ef962af6e272"},"outputs":[{"name":"stdout","output_type":"stream","text":["X = [1. 0. 0.], Predicted = 0\n","X = [0. 1. 0.], Predicted = 1\n","X = [0. 1. 0.], Predicted = 1\n","X = [1. 0. 0.], Predicted = 0\n","X = [0. 0. 1.], Predicted = 2\n","X = [0. 1. 0.], Predicted = 1\n","X = [0. 0. 1.], Predicted = 2\n","X = [1. 0. 0.], Predicted = 0\n","X = [1. 0. 0.], Predicted = 0\n","X = [0. 0. 1.], Predicted = 2\n","X = [0. 1. 0.], Predicted = 1\n","X = [1. 0. 0.], Predicted = 0\n","X = [0. 0. 1.], Predicted = 2\n","X = [0. 1. 0.], Predicted = 1\n","X = [0. 1. 0.], Predicted = 1\n","X = [1. 0. 0.], Predicted = 0\n","X = [0. 1. 0.], Predicted = 1\n","X = [0. 1. 0.], Predicted = 1\n","X = [1. 0. 0.], Predicted = 0\n","X = [1. 0. 0.], Predicted = 0\n"]}],"source":["for i in range(len(Y_test)):\n","  print(\"X = %s, Predicted = %s\" % (Y_test[i], Actual[i]))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}